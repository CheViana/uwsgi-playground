# Monitoring uWSGI stats using InfluxDB/Grafana/telegraf (TIG) - from scratch

## Prerequisite

It might be that reader has typical nginx-uWSGI-Python web app setup and is wondering how to monitor all of that, in production and/or during testing.
I find monitoring uWSGI stats really helps when determining optimal uWSGI server configuration, for comparing different configurations.
Hope this post will be useful for understanding how to setup local monitoring environment of uWSGI web server, and it's possible to setup similar tools in (any?) cloud environment.
In future, I plan to add posts about how to monitor Python web app aspects as well as system resources consumption, using same tools.

## uWSGI stats and monitoring stack

uWSGI can expose stats on separate socket. There are a lot of ways to monitor uWSGI stats. 
Simplest way is to use uwsgitop - https://github.com/xrmx/uwsgitop. However uwsgitop only shows current metrics readings, no history data, just like Linux `top` command. (Some time ago I created a fork of uwsgitop because of encoding-related bug in output, but that bug seems to be fixed now)

I think it's nicer to be able to see uWSGI stats metrics over continuous periods of time as it provides more information than just this moment readings.
It helps to see how the level of load affects web server stats when trying to find best web server configuration.

One option is to use Prometeus with exporter for uWSGI stats, here I'll describe other option - TIG stack.
TIG stack differs from Prometeus mainly in the idea of relying on some other tool to push metrics to time series DB, instead of pulling model which Prometeus uses. Actually, both of the stacks can do push and pull, and there's discussion going on about which method works better for which type of monitoring - https://giedrius.blog/2019/05/11/push-vs-pull-in-monitoring-systems/ . Prometeus is really popular approach as it works well in Kubernetes environment.
For kind of local comparative experiments I'm planning to run on uWSGI web servers in following posts, I don't think there's difference: can use either monitoring stack.
I picked TIG for this post because I have some experience with these technologies, and because Prometeus approach is described elsewhere - https://www.apsl.net/blog/2018/10/01/using-prometheus-monitoring-django-applications-kubernetes/ .  (Prometeus uwsgi-exporter can be found at https://github.com/timonwong/uwsgi_exporter . As of now, it seems to not support reporting of uwsgi worker status which is indeed very useful metric - https://github.com/timonwong/uwsgi_exporter/issues/21)

Here's what will be desribed in this post:
- setup simple uWSGI webserver
- load that webserver using wrk2
- install and run InfluxDB
- install and run telegraf
- install and run Grafana
- create dashboard in Grafana to show uWSGI metrics
- talk a bit about each metric

Most of code and configs found in this tutorial can be found in [repo].

## Simple uWSGI web server

Here's code of "Hello World" uWSGI app in uwsgi-hello-world.py:

    import time


    def application(env, start_response):
        start_response('200 OK', [('Content-Type','text/html')])
        time.sleep(0.25)  # sleep 250 msec
        return [b'Hello World']

And basic uWSGI configs in uwsgi-hello-world-configs.ini:

    [uwsgi]
    http-socket = 127.0.0.1:9090
    wsgi-file = uwsgi-hello-world.py
    master = true
    processes = 4
    threads = 2 
    stats = 127.0.0.1:9191
    stats-http = true

This code doesn't do anything useful. Can use wsgi.py of your Django or Flask server or any other Python web app (wsgi = path/to/Django-app/wsgi.py), should be perfectly alright, and probably more interesting.
uWSGI can be installed as Python package to virtual environment. Let's assume you know how to create and activate Python virtual env (if not, please consult https://virtualenv.pypa.io/en/latest/index.html). 

To install uWSGI Python package:

    > mkvirtualenv --python=python3 uwsgi-playground
    > pip install uWSGI

To run uWSGI server:

    > uwsgi --ini uwsgi-hello-world-configs.ini

Should produce output similar to:

    ...
    uwsgi socket 0 bound to TCP address 127.0.0.1:9090
    *** Operational MODE: preforking+threaded ***
    WSGI app 0 ... ready in 0 seconds ...
    *** uWSGI is running in multiple interpreter mode ***
    spawned uWSGI master process (pid: ...)
    spawned uWSGI worker 1 (pid: ..., cores: 2)
    spawned uWSGI worker 2 (pid: ..., cores: 2)
    spawned uWSGI worker 3 (pid: ..., cores: 2)
    spawned uWSGI worker 4 (pid: ..., cores: 2)
    *** Stats server enabled on 127.0.0.1:9191 fd: ... ***

It means web server has launched and it's listening on port 127.0.0.1:9090.
Can visit hello-world server in local web browser - on http://127.0.0.1:9090/ - will see something like [pic 1].
Can also visit stats endpoint in local web browser - on http://127.0.0.1:9191/  - will see JSON recembling following:

    ...
    "workers": [
        {
			"id":2,
			"pid":...,
			"accepting":1,
			"requests":1,
			"delta_requests":1,
            "avg_rt":71928
            ....
    ]
    ...

uWSGI outputs to console that it processed requests after we visited those pages:

    [pid: ...|app: 0|req: 1/1] 127.0.0.1 () {42 vars in 783 bytes} [Sun Jul 19 20:21:38 2020] GET / => generated 11 bytes in 250 msecs (HTTP/1.1 200) 1 headers in 44 bytes (2 switches on core 0)
    [pid: ...|app: 0|req: 1/2] 127.0.0.1 () {38 vars in 670 bytes} [Sun Jul 19 20:21:38 2020] GET /favicon.ico => generated 11 bytes in 143 msecs (HTTP/1.1 200) 1 headers in 44 bytes (2 switches on core 0)

uWSGI can also be configured to log those lines to a file (see uWSGI options docs on how to set it up).

## Loading web server with benchmark tool wrk2

To keep uWSGI web server busy, let's load uWSGI hello-world server using wrk2 benchmarking tool - https://github.com/giltene/wrk2. Can use any other load generator: here's overview of a bunch of them https://k6.io/blog/comparing-best-open-source-load-testing-tools . I picked wrk2 because I don't need complicated test scenario for this post, otherwise would pick something else. Some load testing tools can be configured to write to InfluxDB as well, which makes observing results of load test real easy.
To install wrk2:

    > git clone https://github.com/giltene/wrk2
    > cd wrk2
    > make

To run wrk2:

    > ./wrk -t2 -c16 -d3600s -R16 http://127.0.0.1:9090/

This command creates 2 threads that try to load :9090 webserver with 16 RPS, keeping 16 HTTP connections open.
It will create load for 3600 sec which is one hour. Feel free to adjust.


## Tools for real-time monitoring: graphana, telegraf, influxdb (also known as TIG stack)

To install all tools locally, execute (on MacOS):

    > brew install influxdb  <-- Database for metrics
    > brew install telegraf  <-- agent-collector of metrics
    > brew install graphana  <-- UI for metrics exploration and plotting

On Linux:


Launch influxDB:

    influxd -config /usr/local/etc/influxdb.conf


Create database for local playground metrics (using CLI in other shell tab):

    influx -precision rfc3339
    Connected to http://localhost:8086 version v1.8.1
    InfluxDB shell version: v1.8.1
    > CREATE DATABASE localmetrics
    > SHOW DATABASES
    name: databases
    name
    ----
    _internal
    localmetrics
    >

It is now possible to run "INSERT ..." command using CLI, which will add metric reading to the database.

We want to have uWSGI stats (data in that JSON) sent to database automatically, e.g. every 5 seconds, and in format that InfluxDB will understand.
Also uWSGI passively exposes stats data on socket 9191, so request on that socket will result in response with stats JSON, but if nobody is executing requests on 9191 socket - stats are not known to anybody (except uWSGI process itself because it uses stats to e.g. know when to respawn worker processes).
Need something that will query uWSGI stats endpoint and send it to InfluxDB database.
This is where Telegraf comes to light. Telegraf has ability to retrieve metrics data, transform it to format InfluxDB understands and send it over to InfluxDB database.
Telegraf has a bunch of input plugins: to watch over system cpu, to read log file tail, to listen to messages on socket, etc, and various web servers integrations, including uWSGI.
Telegraf uWSGI plugin can be found at https://github.com/influxdata/telegraf/tree/master/plugins/inputs/uwsgi and they have quite a list of exposed metrics.
It's a matter of adding few lines to telegraf config and it will consume uWSGI stats.

For now, we will start telegraf with with uWSGI input plugin only.
Let's use telegraf sample-config utility to compose it's configs:

    > telegraf -sample-config --input-filter uwsgi --output-filter influxdb > telegraf.conf
    > cat telegraf.conf
    ...
    # Read uWSGI metrics.
    [[inputs.uwsgi]]
    ## List with urls of uWSGI Stats servers. URL must match pattern:
    ## scheme://address[:port]
    ##
    ## For example:
    ## servers = ["tcp://localhost:5050", "http://localhost:1717", "unix:///tmp/statsock"]
    servers = ["tcp://127.0.0.1:1717"]

    ## General connection timout
    # timeout = "5s"

tcp://127.0.0.1:1717 part doesn't match where our uWSGI exposes stats on. It's http://127.0.0.1:9191. Need to update that in telegraf.conf file.
Another thing that needs to be updated is the address of where to write stats to:

    # Configuration for sending metrics to InfluxDB
    [[outputs.influxdb]]
    ## The full HTTP or UDP URL for your InfluxDB instance.
    ##
    ## Multiple URLs can be specified for a single cluster, only ONE of the
    ## urls will be written to each interval.
    # urls = ["unix:///var/run/influxdb.sock"]
    # urls = ["udp://127.0.0.1:8089"]
    urls = ["http://127.0.0.1:8086"]

    ## The target database for metrics; will be created as needed.
    ## For UDP url endpoint database needs to be configured on server side.
    database = "uWSGI"

I uncommented `urls = ["http://127.0.0.1:8086"]` line and added `database = "uWSGI"` so metrics from uWSGI stats server will flow in separate database.
Resulting config for telegrad is included in repo as telegraf.conf.

To run telegraf:

    > telegraf -config telegraf.conf


Looking in InfluxDB console output, can see:

    2020-07-20T01:18:26.727302Z	info	Executing query	{"log_id": "0O6K1AQG000", "service": "query", "query": "CREATE DATABASE uWSGI"}
    [httpd] 127.0.0.1 - - [19/Jul/2020:21:18:26 -0400] "POST /query HTTP/1.1" 200 57 "-" "Telegraf/1.14.5" e9bd1368-ca26-11ea-8005-88e9fe853b3a 428
    [httpd] 127.0.0.1 - - [19/Jul/2020:21:18:40 -0400] "POST /write?db=uWSGI HTTP/1.1" 204 0 "-" "Telegraf/1.14.5" f1a77b04-ca26-11ea-8006-88e9fe853b3a 137748
    [httpd] 127.0.0.1 - - [19/Jul/2020:21:18:50 -0400] "POST /write?db=uWSGI HTTP/1.1" 204 0 "-" "Telegraf/1.14.5" f79d5380-ca26-11ea-8007-88e9fe853b3a 7695
    [httpd] 127.0.0.1 - - [19/Jul/2020:21:19:00 -0400] "POST /write?db=uWSGI HTTP/1.1" 204 0 "-" "Telegraf/1.14.5" fd928134-ca26-11ea-8008-88e9fe853b3a 8534
    [httpd] 127.0.0.1 - - [19/Jul/2020:21:19:10 -0400] "POST /write?db=uWSGI HTTP/1.1" 204 0 "-" "Telegraf/1.14.5" 0388c512-ca27-11ea-8009-88e9fe853b3a 9345

So telegraf is busy writing uWSGI metrics to database but we can't see them yet. Let's improve on it.
Launch grafana web server:

    > cd path/to/dir/with/installed/graphana
    > bin/grafana-server

Navigating to http://localhost:3000/ in browser opens window with Grafana UI. Login using "admin" "admin" and create new pass as it asks to.
Pick "Configuration -> Data Sources -> Add data source" [pic 2]. Select InfluxDB.
Put "http://127.0.0.1:8086" in HTTP/URL input and database name "uWSGI" in "InfluxDB Details/Database" input [pic 3].
Click on "Save and Test" button in the bottom of the screen, green noty reading "Data source is working" should appear [pic 4].

## Visualize uWSGI metrics

Now Graphana can read metrics from database, let's visualize them.
Grafana dashboard consists of panels, panel can show how particular metric changed in time. There are lots of types of panels but we will only deal with Time Series panel in this tutorial.  
Here's dashboard snapshot with measurements of hello-world app with 4 workers being loaded by artificial users. - https://snapshot.raintank.io/dashboard/snapshot/IFfCGXltm0Z6Kz5T65Vf0UGfEsWEaKpN

To setup uwsgi-monitoring dashboard, can use JSON in uwsgi-dashboard-model.json, and export that to new dashboard:
- Go to "Dashboards -> Manage dashboards", click on "New dashboard".
- Go to Dashboard settings ("wheel" button at the top right of the page with new dashboard)
- In left menu pick "JSON Model"
- past dashboard JSON there and click "Save changes".
[pic 8] and [pic 9]


Alternatively, can create panels one by one by hand:
- Go to "Dashboards -> Manage dashboards", click on "New dashboard"
- click "New panel" [pic 5].
In new panel edit mode, select Query source - InfluxDB.
Modify query builder inputs [as on pic 6]: 
 - From default *uwsgi_workers*
 - Select field(*avg_rt*) mean()
It is important to tell panel that metric it displays is measured in microseconds, in the right column expand "Axes", "Left Y", "Unit" - "microseconds" [pic 7].
Also nice to configure points thickness so that you can see them clearly ("Display" - "Line width" in the right column).
Give some meaningful name to that panel (in top of right column), save panel (click "Apply" in top right corner).
Panel in real time shows avg request time of all uwsgi workers (make sure refresh frequency selector is set to like 10 sec, tiny dropdown in top right corner of dashboard page).

Now can view uWSGI dashboard at http://localhost:3000/dashboard/new?orgId=1&from=now-15m&to=now&refresh=10s
The dashboard https://snapshot.raintank.io/dashboard/snapshot/IFfCGXltm0Z6Kz5T65Vf0UGfEsWEaKpN is monitoring following uwsgi metrics:
- harakiri count
- worker status (busy/idle/cheap/total)
- listen queue size
- workers amount
- worker requests
- in-request sum
- respawn count
- worker avg request time
- worker running time

There are more things that can be monitored: amount of transmitted data for worker, amount of exceptions for worker, etc, which I didn't need or monitor in another ways.
Can also configure memory reporting - how much memory uWSGI consumes. I prefer to watch memory consumption from system monitoring though, along with CPU consumption.
uWSGI even allows to expose your own metrics - never used this though. https://uwsgi-docs.readthedocs.io/en/latest/Metrics.html 
Cheaper subsystem plugin has it's own metrics too, it seems.

### Grafana specifics: time filter and time interval

`$timeFilter`, seen in panel query builder, stands for time range picked in Grafana UI, the period of time for which you want to see metrics.
`$__timeInterval`, seen in panel query builder, stands for time interval. Time interval depends on what's current time range you're looking at in dashboard. It's time interval between 2 nearest dots on series. Looking at 1 hour range in dashboard (put from=now-1h&to=now in URL or use time range picker in upper right corner of dashboard) I see dot at 11:01:02 and next dot is 11:01:06 - time interval is 4 seconds.
Telegraf is configured to send data from uWSGI stats server to InfluxDB every 10 seconds. If time interval is bigger than 10 seconds, one dot in series corresponds to avg/sum/... (set in query which one) of multiple uWSGI stats readings (those that got into time interval).


## uWSGI stats - by metric

### Harakiri count

uWSGI has mechanizm to kill worker if worker executes request for longer than defined time (e.g. 10 sec). It's called "harakiri". To configure it, set uwsgi option `harakiri=10` (in uwsgi.ini), where 10 is time of longest allowed request.
This option can be used to protect from DDoS attacks that exploit long-executing requests, basically flooding website with long-executing requests to the extend website doesn't have capacity (free workers) to serve usual user traffic, all workers are busy executing attackers long-executing requests.
Setting low harakirir can bite you if web server is expected to serve rare long-executing requests. So need to analyze what's longest valid request time. Can consider refactoring code to avoid long-executing requests in worker processes (lots of options depending on partical problem, use uWSGI spooler to send emails, use uWSGI mules, or some kind of separate from webserver task queue for long-executing requests, or worse option - use uWSGI routes to enforce different harakiri values depending on URL path). 

Harakiri panel query is:

    SELECT sum("harakiri_count") FROM "uwsgi_workers" WHERE $timeFilter GROUP BY time($__interval) fill(null)

It shows sum of harakiri event for time interval. Time interval depends on what's current time range you're looking at in dashboard. It's time interval between 2 nearest dots on series. Looking at 1 hour range in dashboard (put from=now-1h&to=now in URL or use time range picker in upper right corner of dashboard) I see dot at 11:01:02 and next dot is 11:01:06 - time interval is 4 seconds.


### Worker status

uWSGI worker can be in few states: 
- idle (not working on request)
- busy (working on requests)
- cheap (see uWSGI cheaper subsystem docs)

I configured Worker status panel to show idle, busy, cheap and total amounts of workers.
Query is:

    SELECT count("status") FROM "uwsgi_workers" WHERE  $timeFilter and "status"='busy' GROUP BY time($__interval) fill(null)

for "busy" series, for other series replace "busy" with "idle" or "cheap", for total - omit status clause (... WHERE  $timeFilter GROUP BY ...).


### Listen queue size

If all uWSGI workers are busy working on requests while new requests are arriving, those new ones are first put in queue (socket listen queue) to wait for next free worker.
Size of listen queue is configurable using option `listen=64` but max allowed value depends on system max socket listen queue size, might need to increase system value first (https://community.webcore.cloud/tutorials/uwsgi_your_server_socket_listen_backlog_is_limited/).

Panel query is:

    SELECT sum("listen_queue") FROM "uwsgi_overview" WHERE $timeFilter GROUP BY time($interval)


### Workers amount

Amount of workers uWSGI is currently running. Makes more sense when cheaper subsystem is in use, or when cluster has multiple web server instances with scaling (all reporting to same DB) - then this count changes.

Workers 1-4 amount query: 

    SELECT count("avg_rt") FROM "uwsgi_workers" WHERE $timeFilter AND ("worker_id"='1' OR "worker_id"='2' OR "worker_id"='3' OR "worker_id"='4') GROUP BY time($__interval) fill(null)

This is indirect metric, it counts how many times `avg_rt` metric was reported for "worker_id"='1' during time interval. It time interval is bigger than 10 sec (telegraf queries uWSGI stats once every 10 sec) - e.g. when time range you're looking at is 6 hours, this actually shows incorrect data. 
Question to figure out if you're curious and don't mind digging into Grafana docs - how to make it show correct data regardless of chosen time range?


### Worker requests

How much requests one worker has executed since worker process was started. When webserver serves requests, this measurement rises smoothly. When worker restarts, it falls to zero.

Query is:

    SELECT mean("requests") FROM "uwsgi_workers" WHERE $timeFilter GROUP BY time($interval), "worker_id"


### In-request sum

How many requests uWSGI is working on right now (across all workers, sum for time interval).
Query:

    SELECT sum("in_request") FROM "uwsgi_cores" WHERE $timeFilter GROUP BY time($interval)


### Respawn count

How many times workers were respawned.
For production system it's recommended to gracefully respawn uwsgi workers after some time, to avoid execessive memory consumption of long-living processes, etc.

To limit amount of executed requets after which to respawn, add in options:

    max-requests=10000
    max-requests-delta=1000

This will respawn worker after 10000+-1000 requests. Delta is random value added to/substracted from max-requests, used not to respawn all workers at the same time.

To limit amount of time passed after which to respawn, add in options:

    max-worker-lifetime=36000
    max-worker-lifetime-delta=3600

Values are in sec. This will respawn worker after 10h+-1h of time passed since last respawn. Delta is random value added to/substracted from max-lifetime, used not to respawn all workers at the same time.

Can use both limits, which one occurs first for particular worker will take effect.

Query;

    SELECT sum("respawn_count") FROM "uwsgi_workers" WHERE $timeFilter GROUP BY time($interval), "uwsgi_host"


### Worker avg request time

Amount of time worker spends on request, on avg. 

Query:

    SELECT mean("avg_rt") FROM "uwsgi_workers" WHERE $timeFilter GROUP BY time($__interval), "worker_id" fill(null)



### Worker running time

How long is worker running, time since last respawn. 

Query:

    SELECT mean("running_time") FROM "uwsgi_workers" WHERE  $timeFilter GROUP BY time($interval), "worker_id"


